{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d98dd7e",
   "metadata": {},
   "source": [
    "# Langchain Intro\n",
    "\n",
    "- LLM powered 어플리케이션 제작을 위한 프레임 워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6da02fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6a45e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ffb69b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CAra4cOU9nKVVbBi1VttkJ9QcI51z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8a1f8e66-38b2-4398-bea0-dd1f0febe977-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 지정할 수 있음 (openAI API들어가면 모델 있음)\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e869f58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나는'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 우리가 외국어로 메시지가 들어오면, 한국어로 번열을 해주는 AI를 만들고 싶다면?\n",
    "\n",
    "msg = input('외국어를 넣으세요')\n",
    "res = llm.invoke(f'한국어로 번역해줘: {msg}')\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8eae48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Tengo hambre... ¿Qué sería bueno comer para el almuerzo?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 56, 'total_tokens': 73, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqNhJtqLHvhL7nJu4aYsZxJGLZDr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--891ff2c5-d8ff-4a3e-8af0-cf186b3682d2-0', usage_metadata={'input_tokens': 56, 'output_tokens': 17, 'total_tokens': 73, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    SystemMessage(content='모든 한국어를 스페인어로 번역해줘'),\n",
    "    HumanMessage(content='배고파.. 점심 뭘 먹는게 좋을까?')\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e23660a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='천재가 된 줄 알았던 그는, 결국 영원한 삶의 수준이 바보로 밖에 안 된다는 것을 깨달았다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 35, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqNiEq5b2fbhHOBcSGSZOU68L5rf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f0fc3668-f102-4df8-9638-74501f151b55-0', usage_metadata={'input_tokens': 35, 'output_tokens': 54, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': '단어에 관련된 한줄 소설을 만들어줘'},\n",
    "    {'role': 'user', 'content': '바보'}\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea41a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|하|루| 종|일| 머|리|속|에서| 떨|리|는| 쪽|지|를| 읽|는|데|,| 그| 안|엔| 한| 마|디|만| 적|혀| 있|었다|.| \"|바|보|야|,| 나| 너|를| 좋|아|해|.\"||"
     ]
    }
   ],
   "source": [
    "# open AI tokenizer 들어가면 확인할 수 있음\n",
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf22e4c",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "- 고정된 문자열과 변수를 조합하여 프롬포트(문자열)를 만드는 방법\n",
    "\n",
    "## Chain\n",
    "- Langchain의 각 구성요소를 묶어서(chaining) 한번에 실행(invoke)할 수 있도록 하는 기능\n",
    "- `a | b | c` 형태로 나옴. 이건 Python 문법이 아니라 Langchain 문법 (LCEL- LanChain Expression Language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c08b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='竹島は韓国の土地です', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 28, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqd9sonO59qY9kTwWSyLfQ2ORTyH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b65e9c80-dbf5-4806-a4fb-07de6cfd7aab-0', usage_metadata={'input_tokens': 28, 'output_tokens': 14, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 채팅을 할 경우에는 ChatPromptTemplate! 챗 프롬포트 템플릿\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages= [\n",
    "     {'role': 'system', 'content': 'Translate Korean to {lang}'},\n",
    "     {'role': 'user', 'content': '{text}'}\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': '일본어', 'text': '독도는 한국땅'})\n",
    "prompt.to_messages()\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b70dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I want to eat a burger', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 26, 'total_tokens': 32, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqfMdMGofwYeZ4adKetbLQVlch2R', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6451c962-1ae0-4eb4-9b07-9bbe4db02bd3-0', usage_metadata={'input_tokens': 26, 'output_tokens': 6, 'total_tokens': 32, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿을 invoke -> llm을 invoke\n",
    "prompt = prompt_template.invoke({'lang': '영어', 'text': '버거 먹고 싶당'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a55d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to eat kimchi stew'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자열을 해석해주는 \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 랭'체인'이라고 부르는 이유\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "chain.invoke({'lang': '영어', 'text': '김치찌개 먹고 싶당'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a33e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화 문장: I felt like our second date wasn't as great as the first one, did you feel the same way?\n",
      "- 한글 번역 문장: 우리 두 번째 데이트가 첫 번째 것만큼 좋지 않았다는 느낌이 들었어, 너도 같이 느꼈니?\n"
     ]
    }
   ],
   "source": [
    "# 2. 단발성 명령 수행은 PromptTemplate! 프롬포트 템플릿\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 10년차 스타 영어 강사입니다. 상황에 맞게 [FORMAT]에 영어 회화를 작성해주세요.\n",
    "상황: {question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화 문장:\n",
    "- 한글 번역 문장:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '소개팅에서 만난 상대가 두번째 데이트에서 별로일 때'})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38b24188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025년 전반기 매출 분석을 위한 EDA(탐색적 데이터 분석) 단계는 다음과 같이 구분할 수 있습니다:\n",
      "\n",
      "1. 데이터 수집 및 준비\n",
      "   - 2025년 전반기(1월~6월) 매출 관련 데이터 확보\n",
      "   - 데이터 소스 확인 (ERP, POS, CSV 파일 등)\n",
      "   - 필요한 변수 선정 (매출액, 거래일, 상품군, 고객 정보 등)\n",
      "\n",
      "2. 데이터 정제 및 전처리\n",
      "   - 결측치 및 이상치 처리\n",
      "   - 날짜 형식 통일 및 기간 필터링\n",
      "   - 중복 데이터 제거\n",
      "   - 필요시 변수 생성 (월, 분기, 고객 등)\n",
      "\n",
      "3. 기초 통계분석\n",
      "   - 전체 매출 규모 및 평균, 중앙값 등 기초 통계량 산출\n",
      "   - 월별, 상품별, 고객군별 매출 집계\n",
      "   - 매출의 분포 확인 (히스토그램, 박스플롯 등)\n",
      "\n",
      "4. 시각화 및 트렌드 분석\n",
      "   - 시간에 따른 매출 추이 시각화 (선그래프 등)\n",
      "   - 주요 상품군 또는 고객군별 매출 비중 파이 차트 또는 도넛 차트\n",
      "   - 계절성 또는 주기성 파악을 위한 분기별/월별 분석\n",
      "\n",
      "5. 세부 분석\n",
      "   - 매출 증감 원인 분석 (신제품 출시, 프로모션 이벤트 등 고려)\n",
      "   - 매출 상위/하위 상품 또는 고객군 분석\n",
      "   - 지역별 또는 채널별 매출 비교 (만약 위치 데이터가 있다면)\n",
      "\n",
      "6. 결론 및 인사이트 도출\n",
      "   - 핵심 매출 패턴 및 이슈 도출\n",
      "   - 향후 분석 방향 또는 추가 데이터 필요성 제안\n",
      "\n",
      "이 단계별로 진행하면 2025년 전반기 매출 현황을 체계적으로 파악할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "당신은 클라이언트의 요구사항을 분석해서 단계를 나눠주는 데이터분석 전문가입니다. \n",
    "사용자의 질문을 EDA에 활용할 수 있도록 단계를 나눠주세요.\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '2025년 전반기 매출 분석'})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^1^.^ 데이터^ 수^집^:^ 먼^저^ ^202^5^년^ 전^반^기^ 동^안^의^ 매^출^ 데이터^를^ 수^집^합니다^.^ 이^ 데이터^는^ 회^사^ 내^부^의^ 매^출^ 시^스^템^이^나^ 데이터^베^이^스^에서^ 얻^을^ 수^ 있^습니다^.\n",
      "\n",
      "^2^.^ 데이터^ 전^처^리^:^ 수^집^한^ 데이터^를^ 정^제^하^고^ 필^요^한^ 변수^들^을^ 추^출^합니다^.^ 매^출^ 데이터^의^ 경우^ 주^문^일^,^ 제^품^명^,^ 가^격^,^ 수^량^ 등^의^ 변수^를^ 포^함^할^ 것^으로^ 예^상^됩니다^.\n",
      "\n",
      "^3^.^ 탐^색^적^ 데이터^ 분^석^ (^EDA^):^ 전^처^리^된^ 데이터^를^ 사용^하여^ 탐^색^적^ 데이터^ 분^석^을^ 수^행^합니다^.^ 이^ 과^정^에서^ 매^출^의^ 트^렌^드^,^ 분^포^,^ 이^상^치^ 등^을^ 확인^할^ 수^ 있^습니다^.\n",
      "\n",
      "^4^.^ 매^출^ 요^약^:^ 매^출^ 데이터^를^ 시^간^대^ 또^는^ 제^품^ 카^테^고^리^별^로^ 요^약^하여^ 전^반^기^ 동^안^의^ 매^출^ 추^이^를^ 살^펴^봅^니다^.\n",
      "\n",
      "^5^.^ 시^각^화^:^ E^DA^의^ 결과^를^ 바^탕^으로^ 시^각^화^를^ 통^해^ 매^출^ 분^석^을^ 진^행^합니다^.^ 그^래^프^,^ 차^트^ 등^을^ 활^용^하여^ 직^관^적^으로^ 이^해^할^ 수^ 있^도^록^ 표^현^합니다^.\n",
      "\n",
      "^6^.^ 인^사^이^트^ 도^출^:^ E^DA^를^ 통^해^ 얻^은^ 결과^를^ 바^탕^으로^ ^202^5^년^ 전^반^기^의^ 매^출^에^ 영^향^을^ 미^치^는^ 요^인^을^ 분^석^하^고^ 인^사^이^트^를^ 도^출^합니다^.\n",
      "\n",
      "^7^.^ 결과^ 보^고^:^ 분^석^한^ 결과^를^ 클^라^이^언^트^에^게^ 보^고^하여^ 전^반^기^ 매^출^에^ 대^한^ 통^찰^력^을^ 제^공^합니다^.^ 필^요^한^ 경우^ 추가^ 분^석^이^나^ 조^치^를^ 제^안^할^ 수^ 있^습니다^.^^"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({'question': '2025년 전반기 매출 분석'}):\n",
    "    print(token, end='^', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d32320ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain은 자연어처리(NLP) 애플리케이션 개발을 위한 오픈소스 프레임워크로, 언어 모델과 다양한 도구들을 쉽게 결합할 수 있도록 돕습니다. 이를 통해 사용자 요청에 맞춘 대화형 인터페이스, 정보 검색, 데이터 처리 등의 복잡한 작업들을 효율적으로 구현할 수 있습니다. 또한, 여러 가지 데이터 소스와 연동하여 맞춤형 AI 솔루션을 개발하는 데 유용한 라이브러리입니다.',\n",
       " 'Langsmith는 인공지능 기반 자연어처리 플랫폼으로, 사용자가 다양한 언어로 쉽게 대화형 애플리케이션을 개발할 수 있도록 지원합니다. 이 서비스는 대화 인터페이스 설계, 모델 훈련, 배포 과정을 간소화하여 개발자가 빠르게 맞춤형 챗봇을 구축할 수 있게 도와줍니다. 또한, 사용자 친화적인 도구와 통합 기능을 제공하여 기업 및 개발자가 효율적으로 인공지능 솔루션을 활용할 수 있도록 합니다.',\n",
       " 'LangGraph는 자연어 처리와 지식 그래프 기술을 결합한 도구로, 언어 데이터의 의미와 연결 구조를 시각화하고 분석하는 데 사용됩니다. 이를 통해 텍스트 내의 개체, 관계, 개념 간의 복잡한 연결을 쉽게 파악할 수 있습니다. LangGraph는 연구자와 개발자가 자연어 이해 및 지식 기반 애플리케이션을 구축하는 데 유용하게 활용됩니다.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}에 대해서 3문장으로 설명해줘')\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 여러개를 걸 수 있는 batch\n",
    "chain.batch([\n",
    "    {'topic': 'Langchain'},\n",
    "    {'topic': 'Langsmith'},\n",
    "    {'topic': 'Langgraph'},\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
