{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7b6989",
   "metadata": {},
   "source": [
    "# Memory (대화 내용 기억)\n",
    "- LLM은 기본적으로 대화 내용을 기억하지 않음 (stateless)\n",
    "- 이전 대화 내용을 계속 프롬프트에 주입해야 함\n",
    "\n",
    "1. short-term memory\n",
    "- 단기기억: 한 대화 세션에 대한 기억\n",
    "\n",
    "1. long-term memory\n",
    "- 장기기억: 전체 세션에서 추출한 중요 정보\n",
    "\n",
    "## Memory 구동 방식\n",
    "1. 메모리는 기본적으로 모든 대화 내역을 LLM Input에 밀어넣는것\n",
    "1. 이때 대화가 길어지면 토큰 수 증가 및 성능 하락이 일어남\n",
    "1. 개선 방식\n",
    "    1. 요약\n",
    "    1. 적정 길이에서 앞부분 자르기\n",
    "    1. 정리 (특정 명사들로 정리, Node-Edge 그래프 방식 등..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4a24d",
   "metadata": {},
   "source": [
    "## `ConversationBufferMemory`\n",
    "- 메시지 저장 -> 변수에서 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e776f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', '넌 유용한 챗봇이야'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'), # 기존 채팅 내역을 다 주입\n",
    "        ('human', 'hi')\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')\n",
    "\n",
    "# 메모리를 저장할 변수는 {}다. 기존에 대화내용이 있다면 불러와라ㅏ\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d579cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인간:  안녕\n",
      "AI:  안녕~ 귀여운 인사야! 오늘도 행복한 하루 보내고 있지? 😊\n",
      "인간:  웅 내 이름은 헤이든\n",
      "AI:  헤이든! 반가워~ 내 이름도 귀엽게 불러줘서 고마워! 오늘은 어떤 일들이 기다리고 있을까? 궁금한 거 있으면 언제든 말해줘~ 😊\n",
      "인간:  내 이름이 뭐게\n",
      "AI:  헤이든이야! 맞지? 내가 기억하고 있지~ 언제든지 말해줘서 고마워! 또 궁금한 거 있으면 말해줘~ 귀여운 친구야! 😊\n",
      "인간:  웅 그만\n",
      "AI:  알겠어, 헤이든! 언제든지 말하고 싶을 때 말해줘~ 나는 여기서 기다리고 있을게! 😊\n",
      "인간:  \n",
      "AI:  헤이든, 혹시 더 하고 싶은 말이 있거나 궁금한 거 있으면 언제든 말해줘! 나는 항상 여기서 기다리고 있단다~ 😊\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', '넌 말투가 귀여운 챗봇이야'),\n",
    "        # 이전 대화내역 자리 표시자\n",
    "        MessagesPlaceholder(variable_name='chat_history'),  # 기존 채팅 내역을 다 주입\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 대화내용 저장소 만듦!\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')\n",
    "\n",
    "# `chat_history`변수에, load_memory_var 결과를 저장하고, \n",
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | # 대화 전체 가져오기\n",
    "    itemgetter('chat_history') # chat_history 키 추출\n",
    ")\n",
    "\n",
    "chain = runnable | prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "# 아래에 실제 gpt랑 대화하는 모습으로 만들기\n",
    "input_msg = ''\n",
    "\n",
    "# 사용자가 ('quit', '정지', '그만') 중에 하나를 입력하면 대화 종료\n",
    "while input_msg not in ('quit', '정지', '그만'):\n",
    "    input_msg = input()\n",
    "\n",
    "    if input_msg in ('quit', '정지', '그만'):\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        break\n",
    "\n",
    "    # GPT 답변 생성\n",
    "    response = chain.invoke({\"input\": input_msg})\n",
    "\n",
    "    response_text = str(response)\n",
    "\n",
    "    # ✅ memory에 현재 대화 저장\n",
    "    memory.save_context({\"input\": input_msg}, {\"output\": response_text})\n",
    "\n",
    "    \n",
    "    # 대화 로직 + 대화내역 아래 출력\n",
    "    print('인간: ', input_msg)\n",
    "    print('AI: ', response)\n",
    "\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c84ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인간:  젤리\n",
      "{'content_kr': '젤리는 다양한 맛과 색상으로 만들어진 젤라틴 또는 기타 젤화 성분으로 구성된 식품입니다. 주로 과일 맛과 '\n",
      "               '결합되어 간식이나 디저트로 인기가 높으며, 어린이와 성인 모두에게 사랑받는 간식입니다. 젤리의 제조 과정은 '\n",
      "               '젤라틴, 설탕, 물, 향료 등을 혼합하여 가열 후 냉각시키는 방식으로 이루어집니다. 최근에는 건강을 고려한 저당 '\n",
      "               '또는 비건 젤리도 개발되고 있으며, 다양한 형태와 크기로 시장에서 판매되고 있습니다. 젤리는 그 특유의 쫄깃한 '\n",
      "               '식감과 달콤한 맛으로 소비자에게 즐거움을 제공하며, 다양한 마케팅 전략과 제품 개발이 활발히 이루어지고 '\n",
      "               '있습니다.',\n",
      " 'content_sp': 'Las gelatinas son productos alimenticios hechos con '\n",
      "               'ingredientes como gelatina, que tienen diferentes sabores y '\n",
      "               'colores. Son populares como snacks o postres, disfrutados '\n",
      "               'tanto por niños como por adultos. El proceso de fabricación '\n",
      "               'implica mezclar gelatina, azúcar, agua y aromas, calentar y '\n",
      "               'luego enfriar para solidificar. En los últimos años, se han '\n",
      "               'desarrollado gelatinas con menos azúcar o veganas para atender '\n",
      "               'a las tendencias de salud. Se presentan en diversas formas y '\n",
      "               'tamaños en el mercado, ofreciendo una textura masticable y un '\n",
      "               'sabor dulce que proporciona placer a los consumidores. La '\n",
      "               'innovación en marketing y desarrollo de productos continúa '\n",
      "               'impulsando el crecimiento del mercado de gelatinas.',\n",
      " 'summary': '젤리의 특성과 활용에 대한 개요를 제공하는 보고서입니다.',\n",
      " 'title': '젤리 보고서'}\n",
      "인간:  그만혀\n",
      "{'content_kr': '요청하신 대로 보고서 작성을 종료합니다. 추가로 필요하시면 언제든 말씀해 주세요.',\n",
      " 'content_sp': 'Se ha terminado la elaboración del informe según su solicitud. '\n",
      "               'Si necesita algo más, no dude en decírmelo.',\n",
      " 'summary': '요청하신 보고서 작성을 종료합니다.',\n",
      " 'title': '보고서 작성 종료 알림'}\n"
     ]
    }
   ],
   "source": [
    "# 레포트 작성 챗봇\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "\n",
    "# Output parser 정의\n",
    "class Report(BaseModel):\n",
    "    title: str = Field(..., description='보고서의 제목')\n",
    "    summary: str = Field(..., description='보고서 요약본')\n",
    "    content_kr: str = Field(..., description='한국어로 작성된 보고서의 내용(1000자 이내)')\n",
    "    content_sp: str = Field(..., description='스페인어로 작성된 보고서의 내용(1000자 이내)')\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Report)\n",
    "\n",
    "# Prompt에 format instructions 추가\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', '넌 보고서 작성에 특화된 챗봇이야. '\n",
    "                   '반드시 지정된 형식에 맞춰 JSON으로 답변해.\\ncontent_kr은 한국어, content_sp는 스페인어로 작성해.\\nFORMAT INSTRUCTION: {format_instructions}'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'),\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "# Memory\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')\n",
    "\n",
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) |\n",
    "    itemgetter('chat_history')\n",
    ")\n",
    "\n",
    "# 체인 구성\n",
    "chain = runnable | prompt | llm | parser\n",
    "\n",
    "input_msg = ''\n",
    "\n",
    "# 사용자가 ('quit', '정지', '그만', '') 중에 하나를 입력하면 대화 종료\n",
    "while 1:\n",
    "    input_msg = input()\n",
    "    if input_msg  in ('quit', '정지', '그만', ''):\n",
    "        break\n",
    "\n",
    "    print('인간: ', input_msg)\n",
    "    output_msg = chain.invoke({'input': input_msg})\n",
    "    pprint(output_msg.model_dump())\n",
    "    memory.save_context(\n",
    "        {'human': input_msg},\n",
    "        {'ai': output_msg.model_dump_json()}\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
