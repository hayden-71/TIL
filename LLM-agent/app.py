# app.py
import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ------------------------
# 1. ë¬¸ì„œ ë¡œë”© & ë²¡í„° ìŠ¤í† ì–´
# ------------------------
loader = DirectoryLoader(
    "./data/",
    glob="Friends*.pdf",   # Friends*.pdf íŒŒì¼ë§Œ ë¡œë”©
    loader_cls=PyMuPDFLoader
)
docs = loader.load()

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400,
    chunk_overlap=50,
)
splits = text_splitter.split_documents(docs)

embedding = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(documents=splits, embedding=embedding)
retriever = vectorstore.as_retriever(search_kwargs={"k": 2})

# ------------------------
# 2. Streamlit UI
# ------------------------
st.title("ğŸ“º Friends ì˜ì–´ ì„ ìƒë‹˜ QA")
st.write("í•œêµ­ì–´ë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ê´€ë ¨ëœ ì˜ì–´ ëŒ€ì‚¬ì™€ ë²ˆì—­ì„ ë³´ì—¬ì¤ë‹ˆë‹¤!")

user_question = st.text_input("ğŸ‘‰ í•œêµ­ì–´ë¡œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

if user_question:
    results = retriever.get_relevant_documents(user_question)

    # ğŸ”¹ ë¬¸ì¥ ì—¬ëŸ¬ ê°œë¥¼ í•©ì³ì„œ í•œ ë²ˆë§Œ LLM í˜¸ì¶œ
    combined_text = "\n".join([doc.page_content for doc in results])

    prompt = f"""
ë„ˆëŠ” Friendsë¥¼ ì¢‹ì•„í•˜ëŠ” ì¹œì ˆí•œ ì˜ì–´ ì„ ìƒë‹˜ì´ì•¼.
ì•„ë˜ ëŒ€ì‚¬ë“¤ì„ ì˜ì–´ ì›ë¬¸ê³¼ í•œêµ­ì–´ ë²ˆì—­ ìŒìœ¼ë¡œ ë³´ì—¬ì¤˜.
í˜•ì‹:
ì˜ì–´ [ëŒ€ì‚¬]
í•œêµ­ì–´ [ë²ˆì—­]

ë§ˆì§€ë§‰ì—ëŠ” ì¤‘ìš”í•œ ì˜ì–´ í‘œí˜„ì„ ì§§ê²Œ ì„¤ëª…í•´ì¤˜.

ëŒ€ì‚¬:
{combined_text}
    """

    llm = ChatOpenAI(model="gpt-4.1-mini", temperature=0)

    st.subheader("ê²°ê³¼:")
    # ğŸ”¹ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
    with st.spinner("ë²ˆì—­ ì¤‘..."):
        response_container = st.empty()
        full_text = ""
        for chunk in llm.stream(prompt):
            full_text += chunk.content
            response_container.markdown(full_text)